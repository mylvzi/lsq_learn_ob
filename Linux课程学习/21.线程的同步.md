>互斥是为了`保证资源安全`, 但是过度互斥会导致资源不能被高效实用
>同步是为了`保证顺序`, 可以保证资源的高效实用

# 一.同步的相关接口
>如何理解`同步机制`
![[Pasted image 20251225140626.png]]
* 为了防止一个线程持续,恶意的不断获取共享资源,导致其他线程无法访问,只能一直阻塞等待,影响效率, 需要给所有线程提供一个`获取资源的顺序`, 这个顺序通过`队列`实现, 规定线程获取资源的顺序
* 在队列中的线程, 不能一直去执行判断操作(锁资源是否被释放), 太吃cpu资源了,而是由持有锁资源的线程, 提供一种通知机制(我要释放锁资源了), 来唤醒在等待的线程


`条件变量 : 实现线程的同步`
```c
// 1.销毁条件变量
int pthread_cond_destroy(pthread_cond_t *cond);

// 2.条件变量的初始化
int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr);
pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
// 3.条件变量的等待
int pthread_cond_timedwait(pthread_cond_t *restrict cond,pthread_mutex_t *restrict mutex,
							const struct timespec *restrict abstime);
int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);

// 4.唤醒条件变量
int pthread_cond_broadcast(pthread_cond_t *cond);
int pthread_cond_signal(pthread_cond_t *cond);
```

>深刻理解为为什么`pthread_cond_wait`的第二个参数是`锁`
```c++
// 1.没有锁
pthread_mutex_lock(&mtx);
while (queue.empty()) {
    pthread_cond_wait(&cond);// 消费者目前持有锁, 但是判断条件成立,需要等待
}                            // 但是结束等待的条件是"生产者唤醒",但是生产者由于没有锁,就不会写入数据,                              // 所以消费者永远不会被唤醒
							// 为了避免"沉睡",一旦等待,就会释放拥有的锁资源  
consume();
pthread_mutex_unlock(&mtx);

// 2.有锁
pthread_mutex_lock(&mtx);
while (queue.empty()) {
    pthread_cond_wait(&cond, &mtx);
}
consume();
pthread_mutex_unlock(&mtx);
```
* `pthread_cond_wait` 的本质不是“等待”，而是一个“原子地：释放锁 + 休眠 + 被唤醒后重新加锁”的操作。
* 锁的本质是**对资源的保护**(互斥),一旦一个线程持有锁, 就等于持有了这个被保护的资源, 其他线程都会被加入等待队列, 但我们需要知道这个资源什么时候被唤醒, 且被唤醒的是那个资源, `pthread_cond_wait`提供了唤醒机制, 参数中需要传递锁本质上是决定**唤醒哪个资源**
# 2.生产者消费者模型
>生产者消费者模型 : `多执行流`并发的模型
>记住`321`原则即可
![[Pasted image 20251225195300.png]]
`1` : 一个交易场所(一个特殊数据结构的内存区域, 负责写入,拿取数据)
`2` : 两个角色(生产者和消费者)
`3` : 三种关系 : 生产者与生产者, 消费者与消费者, 生产者与消费者

>基于BlockingQueue实现的生产者消费者模型
```c++
/*
    基于阻塞队列实现的"生产者消费者模型"
 */
#include <iostream>
#include <queue>
const int defaultCap = 5;
template <typename T>

class BlockingQueue
{
private:
    bool IsFull()
    {
        return _bq.size() == _max_cap;
    }

    bool IsEmpty()
    {
        return _bq.empty();
    }
public:
    BlockingQueue(int cap = defaultCap):_max_cap(cap)
    {
        pthread_mutex_init(&_mutex, NULL);
        pthread_cond_init(&_p_cond, NULL);
        pthread_cond_init(&_c_cond, NULL);

    };

    // 生产者存入数据
    void Put(T &in)
    {
        pthread_mutex_lock(&_mutex);
        while(IsFull()) // 队列满了--无法继续放入数据--生产者阻塞--条件变量  while:防止伪唤醒
        {
            // 等待是在临界区等待的  目前仍然持有锁资源  那消费者就无法访问bq, 死锁了
            // 所以,在wait的时候,会先释放当前持有的锁资源
            // 同时,被唤醒之后,也会重新去竞争锁资源
            pthread_cond_wait(&_p_cond, &_mutex);
        }

        // 1.不未满 || 被唤醒
        _bq.push(in);
        pthread_cond_signal(&_c_cond); // 唤醒消费者
        pthread_mutex_unlock(&_mutex);
    }

    // 消费者消费数据
    void Take(T *out)
    {
        pthread_mutex_lock(&_mutex);
        while(IsEmpty()) // bq为空  阻塞等待
        {
            pthread_cond_wait(&_c_cond, &_mutex);
        }

        // 1.不为空 || 被唤醒
        *out = _bq.front();
        _bq.pop();
        pthread_cond_signal(&_p_cond); // 唤醒生产者
        pthread_mutex_unlock(&_mutex);
    }
    ~BlockingQueue()
    {
        pthread_mutex_destroy(&_mutex);
        pthread_cond_destroy(&_p_cond);
        pthread_cond_destroy(&_c_cond);
    };
public:
    std::queue<T> _bq;// 队列 队列本身就是一个共享资源(被多个线程看到)
    int _max_cap; // 最大容量  用于判断是否为满
    pthread_mutex_t _mutex; // 互斥锁
    pthread_cond_t _p_cond; // 生产者条件变量
    pthread_cond_t _c_cond; // 消费者条件变量
};
```

**不仅仅可以传输数据, 也可以传输任务**
Producter : 产生任务
Consumer : 执行任务
```c++
#include <iostream>
#include "BlockingQueue.hpp"
#include <unistd.h>
#include <pthread.h>
#include <functional>
// 使用回调函数
using Task = std::function<void()>;

void Print()
{
    std::cout << "i am a download task" << std::endl;
}
// 消费者
void* Consume(void* arg)
{
    auto* bq = (BlockingQueue<Task>*)arg;
    while(true)
    {
        Task task;
        bq->Take(&task);// 取出任务
        task(); // 执行任务
        sleep(1);
    }
}

// 生产者
void* Product(void* arg)
{
    auto* bq = (BlockingQueue<Task>*)arg;
    while(true)
    {
        bq->Put(Print);
        std::cout << "i am pro, i put a task..." << std::endl;
        sleep(1);
    }
}
int main()
{
    BlockingQueue<Task> bq;

    pthread_t p1;
    pthread_t c1;

    pthread_create(&p1, NULL, Product, &bq);
    pthread_create(&c1, NULL, Consume, &bq);

    pthread_join(p1, NULL);
    pthread_join(c1, NULL);

    return 0;
}
```
* 需要让生产者和消费者看到同一个队列  队列就是一个共享资源  需要进行维护(互斥 + 同步)
* 两个消费者,一个生产者,其中一个消费者事先被唤醒,且拿到锁资源,最后在释放, 第二个消费者,还在临界区里面,一旦上一个消费者释放锁,这个消费者就可能拿到锁资源,向后执行,但此时队列为空!!!
* 为什么`wait`操作要在临界区内部?生产者消费者最大的特点就是**需要先判断资源是否符合条件(为空/为满)**,这个资源就是队列,所以必须进入共享资源才可以判断,
* `pthread_cond_t` : 条件变量就是**身份标识**

`如何理解高效`
生产者消费者模型之所以高效,不是因为生产者和消费者之间变得高效了,而是因为可以`并发执行`
生产者生产的数据是来自于外部的, 他主要有两种功能:
1. 获取数据
2. 写入数据

获取数据有可能是一个比较耗时的操作(比如从网络等待数据),而向队列写入数据却比较快, 如果只有一个生产者, 效率会很慢, 如果有多个生产者, 就可以使用`多消费者`模型, 多个消费者同时等待数据到来, 一个消费者专门写入数据;

消费者同理, 从队列中获取数据很简单, 但是处理任务会比较复杂, 多个消费者协调,可以加快处理任务的速度

![[Pasted image 20251225203628.png]]
# 3.信号量&&环形队列实现线程间同步
## 环形队列
[多线程编程设计模式(单例,阻塞队列,定时器,线程池)_多线程设计模式-CSDN博客](https://blog.csdn.net/Mylvzi/article/details/135218801?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522f930b670a0e89adb9de6b00f7d971ae1%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=f930b670a0e89adb9de6b00f7d971ae1&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-5-135218801-null-null.nonecase&utm_term=%E7%94%9F%E4%BA%A7%E8%80%85&spm=1018.2226.3001.4450)
```c
rear = (rear + 1) % q.size();
front = (front + 1) % q.size();
cnt; // 用于判满
```
![[Pasted image 20251231171221.png]]

## 信号量相关接口
`sem_init : 初始化一个没有名字的信号量`
```c
int sem_init(sem_t *sem, int pshared, unsigned int value);
```
* 未命名的信号量 : 他的名字就是参数sem的地址!想让线程通信, 就必须看到同一份共享内存, 要么在IPC表,要么制定一个地址
* `sem_t *sem` : 信号量对象的地址
* `int pshared` : 是一个标记位, `0`表示只在同一个进程内部的线程之间共享; `1`表示在不同进程之间共享(这个sem必须在一段shm内, 比如fork后子进程会看到父进程的shm)
`sem_destroy : 销毁一个未命名的信号量`
```c
int sem_destroy(sem_t *sem);
```
`sem_wait : lock a unnamed semphore  P操作`
```c
int sem_wait(sem_t *sem);
```
* sem本质就是一个计数器, sem_wait等价于`decrement`
* 如果信号量的值=0, 调用sem_wait的线程将会阻塞,直到sem>0或者中断处理
`sem_post : unlock a semphore V操作`
```c
int sem_post(sem_t *sem);
```
* 如果sem_post之后, sem > 0, 因调用sem_wait而block的线程会被唤醒

## 环形队列 + 信号量实现线程间同步
>宏观上并发, 局部上保护
* 绝大多数时间 : 队列不为空 || 队列不为满  -->多个线程可以同步访问
* 少数时间:
		* 队列满 : 先让消费者消费
		* 队列空 : 先让生产者生产
* 共享资源就是环形队列

>如何sem_init
* 生产者 : 资源就是有多少个`未使用的空间(空间资源)`  P : 消耗空间资源(新增数据资源)space_sem--  V : 新增空间资源 data_sem++
* 消费者 : 有多少个可使用的`数据资源` P : 消耗一个数据资源(新增空间资源) data_sem-- V : 新增数据资源(消耗空间资源)  space_sem++

>“信号量把某类条件（资源可用性）  
	直接编码进同步原语本身，  
	wait 操作即完成条件判断与阻塞, 故而不需要`加锁判断资源是否可用`”

```c++
#include <iostream>
#include <queue>
#include <functional>
#include <semaphore.h>
#include <unistd.h>
#include <vector>
#include <pthread.h>

template <typename T>
class RingQueue
{
private:
    void P(sem_t &sem)
    {
        sem_wait(&sem);
    }

    void V(sem_t &sem)
    {
        sem_post(&sem);
    }
public:
    void Put(const T &in)
    {
        // 生产者生产数据
        P(_space_sem);
        pthread_mutex_lock(&_p_mutex);

        _ringqueue[_front] = in;
        _front = (_front + 1) % _max_cap;
    
        pthread_mutex_unlock(&_p_mutex);
        V(_data_sem);
    }

    void Take(T *out)
    {
        // 消费者消费数据
        P(_data_sem);
        pthread_mutex_lock(&_c_mutex);

        *out = _ringqueue[_rear];
        _rear = (_rear + 1) % _max_cap;

        pthread_mutex_unlock(&_c_mutex);
        V(_space_sem);
    }
public:
    RingQueue(int maxcap):
        _ringqueue(maxcap), _max_cap(maxcap), _front(0), _rear(0)
    {
        // 信号量初始化
        sem_init(&_space_sem, 0, _max_cap);
        sem_init(&_data_sem, 0, 0);
        
        // 锁初始化
        pthread_mutex_init(&_c_mutex, NULL);
        pthread_mutex_init(&_p_mutex, NULL);
    }
    ~RingQueue()
    {
        sem_destroy(&_space_sem);
        sem_destroy(&_data_sem);

        pthread_mutex_destroy(&_c_mutex);
        pthread_mutex_destroy(&_p_mutex);
    }
private:
    std::vector<T> _ringqueue;
    int _max_cap;
    int _front;
    int _rear;

    sem_t _space_sem;
    sem_t _data_sem;

    pthread_mutex_t _c_mutex;
    pthread_mutex_t _p_mutex;

};
```

# 线程池实现
```c++
#include <iostream>
#include <unistd.h>
#include <string>
#include <vector>
#include <queue>
#include <functional>
#include "Thread.hpp"

using namespace ThreadMoudle;
/*
    线程池实现
*/

// using func_t = std::function<void()>;

template<typename T>
class ThreadPool
{
private:
    void LockQueue()
    {
        pthread_mutex_lock(&_mutex);
    }

    void UnLockQueue()
    {
        pthread_mutex_unlock(&_mutex);
    }

    void Wake()
    {
        pthread_cond_signal(&_cond);
    }

    bool IsEmpty()
    {
        return _task_queue.empty();
    }

    void Sleep()
    {
        pthread_cond_wait(&_cond, &_mutex);
    }

    void WakeUpAll()
    {
        pthread_cond_broadcast(&_cond);
    }
public:
    ThreadPool(int threadnum):
        _isRunning(false), _sleep_Thread_num(0), _thread_num(threadnum)
    {
        pthread_mutex_init(&_mutex, NULL);
        pthread_cond_init(&_cond, NULL);
    }

    // 线程池初始化
    void Init()
    {
        // 绑定要执行的任务
        func_t func = std::bind(&ThreadPool::HandlerTask, this, std::placeholders::_1);
        for(int i = 0; i < _thread_num; i++)
        {
            std::string name = "thread-" + std::to_string(i + 1);
            _threads.emplace_back(name, func);
            std::cout << name << " 初始化成功" << std::endl;
        }
    }
    // 线程池启动
    void Start()
    {
        _isRunning = true;
        for(auto &thread : _threads)
        {
            thread.Start();
            std::cout << thread.Name() << " 启动成功" << std::endl;
        }
    }

    // 向任务队列中存储任务
    void Equeue(const T &in)
    {
        LockQueue();
        if(_isRunning)
        {
            _task_queue.push(in);
            // 唤醒线程 -- 必须有正在因为_cond而阻塞的线程
            if(_sleep_Thread_num > 0)
                Wake();
        }
        UnLockQueue();
    }

    // 线程从任务队列中取出任务并执行
    void HandlerTask(const std::string &name)
    {
        while(true)
        {
            LockQueue();
            while(IsEmpty() && _isRunning)
            {
                _sleep_Thread_num++;
                Sleep();
                _sleep_Thread_num--;
            }

            if(IsEmpty() && !_isRunning)
            {
                UnLockQueue();
                break;
            }
            // 不为空
            T t = _task_queue.front();
            _task_queue.pop();
            UnLockQueue();
            t();// 执行任务肯定是在加锁外面执行
            std::cout << name << ": " << t.result() << std::endl;
        }
    }

    void Stop()
    {
        // 必须保证任务队列中没有任务, 且没有正在等待的线程
        LockQueue();
        _isRunning = false;
        WakeUpAll();
        UnLockQueue();
    }
    ~ThreadPool()
    {
        pthread_mutex_destroy(&_mutex);
        pthread_cond_destroy(&_cond);
    }
private:
    std::vector<Thread> _threads; // 线程池
    std::queue<T> _task_queue; // 任务队列(共享资源)
    
    int _thread_num; // 线程数量
    int _sleep_Thread_num; // 因cond阻塞的线程数目
    bool _isRunning; // 标记线程池是否仍在工作
    pthread_mutex_t _mutex; // 保护共享资源
    pthread_cond_t _cond; // 条件变量
};
```
>几个细节

`Stop中为什么要wakeupall`
需要考虑到线程状态的多样性, stop会首先将_isRunning置于false, 目的是`释放线程池中的所有资源`
即线程池中不能有`正在阻塞 的线程`
线程的状态有三种:
```c
// 1.持有锁
Lock()
// ...会在if中看到isrunning被置为false  退出

// 2.准备持有锁
// ...
Lock()
// 会在while中看到isrunning被置为false  退出

// 3.正在阻塞
// 永远看不到isrunning发生变化 -- 无法退出
```

* 线程池本质上也是一个**生产者消费者模型**, 也遵循`321`原则