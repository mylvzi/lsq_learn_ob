太棒了！“纸上得来终觉浅，绝知此事要躬行”。对于 Docker 和 K 8 s 这种偏底层的架构技术，**“动手做 Demo”是建立系统抽象能力最快的方式**。

结合你作为测试人员关注的**“高可用”、“灰度发布”**等核心诉求，我为你设计了一个**“从单体到集群，再到灰度实战”的四步递进式 Demo**。

### 🛠️ 课前准备：环境搭建
为了最快地上手，不需要去买云服务器。如果你使用的是 Windows 或 Mac，请直接下载并安装 **Docker Desktop**。
1. 安装完成后，你不仅拥有了 Docker 环境。
2. 在 Docker Desktop 的设置（Settings）中，找到 **Kubernetes** 选项卡，勾选 **"Enable Kubernetes"** 并重启。
3. 这样你的电脑上就有了一个单节点的 K 8 s 迷你集群！

打开终端（Terminal/CMD），输入以下命令验证：
```bash
docker --version    # 验证 Docker 是否就绪
kubectl version     # 验证 K8s 命令行工具是否就绪
```

---

### 🟢 Demo 1：Docker 初体验 —— 把代码变成“集装箱”
**目标**：理解镜像（Image）和容器（Container）的关系，体验“一次构建，到处运行”。

**第一步：写一个极简的 Web 服务**
新建一个文件夹叫 `my-app`，在里面新建一个文件 `app.py`（Python 代码）：
```python
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello():
    return "Hello, 我是 V1 版本！"

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```
再新建一个 `requirements.txt`：
```text
Flask==2.0.1
Werkzeug==2.2.2
```

**第二步：编写 Dockerfile（造集装箱的图纸）**
在同一个目录下新建一个名为 `Dockerfile` 的文件（没有后缀）：
```dockerfile
# 1. 基础环境：我们需要一个带 Python 的操作系统
FROM python:3.9-slim
# 2. 把当前目录的代码复制到容器里的 /app 目录
COPY . /app
# 3. 设置工作目录
WORKDIR /app
# 4. 安装依赖
RUN pip install -r requirements.txt
# 5. 告诉容器启动时执行什么命令
CMD ["python", "app.py"]
```

**第三步：构建与运行**
在终端进入该目录，执行：
```bash
# 根据图纸构建镜像（打包装箱），命名为 myapp:v1
docker build -t myapp:v1 .

# 运行容器：把本机的 8080 端口映射到容器的 8080 端口
docker run -d -p 8080:8080 --name my-test-app myapp:v1
```
打开浏览器访问 `http://localhost:8080`，你会看到：“Hello, 我是 V 1 版本！”。
*💡 测试视角抽象：以后开发交接给你的就是这个 `myapp:v1` 镜像，你不需要再痛苦地配置 Python 环境了。*

---

### 🟡 Demo 2：K 8 s 基础 —— 让“指挥家”接管容器
**目标**：理解 K 8 s 的“声明式 API”，体验 K 8 s 的**故障自愈（高可用）**能力。

现在我们要把刚才的 Docker 容器交给 K 8 s 来管理。

**第一步：编写 K 8 s 部署文件（告诉指挥家你的期望）**
新建一个文件 `deployment.yaml`：
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 3 # 【关键】我期望有 3 个副本（3个容器同时跑）
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:v1
        imagePullPolicy: IfNotPresent # 使用本地刚刚打包的镜像
        ports:
        - containerPort: 8080
```

**第二步：提交给 K 8 s 并观察**
```bash
# 提交声明
kubectl apply -f deployment.yaml

# 查看 K8s 创建的 Pod（K8s 中运行容器的最小单元）
kubectl get pods
```
你会看到 3 个 Pod 正在运行。

**第三步：破坏性测试（体验自愈能力）**
作为测试，我们来搞点破坏。复制其中一个 Pod 的名字（比如 `myapp-deployment-xxxxx`），然后强制删除它：
```bash
kubectl delete pod <你复制的Pod名字>
```
立刻再次运行 `kubectl get pods`。你会神奇地发现，K 8 s 瞬间又新建了一个 Pod，始终维持着 3 个副本的总数！
*💡 测试视角抽象：这就是线上高可用的基石。机器宕机？进程崩溃？K 8 s 会自动帮你拉起来。*

---

### 🟠 Demo 3：K 8 s 进阶 —— 暴露服务与负载均衡
**目标**：理解 K 8 s 的 Service（服务发现），让外部能访问这 3 个容器。

**第一步：编写 Service 文件**
新建 `service.yaml`：
```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: NodePort # 暴露给外部访问
  selector:
    app: myapp   # 自动寻找带有 app:myapp 标签的 3 个 Pod
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080 # 固定本机的 30080 端口
```

**第二步：应用并访问**
```bash
kubectl apply -f service.yaml
```
现在，打开浏览器访问 `http://localhost:30080`，你依然能看到页面。但实际上，你的请求被 K 8 s 的 Service **自动负载均衡**到了背后的 3 个 Pod 中的某一个上。

---

### 🔴 Demo 4：测试高阶实战 —— 简易“灰度发布”
**目标**：结合你最关心的灰度能力，用 K 8 s 原生方式实现流量按比例切分。

**第一步：开发 V 2 新版本**
修改 `app.py` 中的代码：
```python
    return "Hello, 我是 V2 版本！！！(新功能)"
```
重新打包一个 V 2 镜像：
```bash
docker build -t myapp:v2 .
```

**第二步：部署 V 2 版本的“金丝雀（Canary）”**
新建一个 `canary.yaml`，注意我们只部署 **1 个副本**的 V 2：
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-canary
spec:
  replicas: 1 # 只有 1 个 V2 副本
  selector:
    matchLabels:
      app: myapp # 【关键】标签依然是 app:myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:v2
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
```
提交部署：`kubectl apply -f canary.yaml`

**第三步：验证灰度效果**
现在，K 8 s 集群里有 3 个 V 1 的 Pod，和 1 个 V 2 的 Pod。因为它们的标签都是 `app:myapp`，Service 会把流量随机打给这 4 个 Pod。

在终端里疯狂用 `curl` 访问（或者在浏览器里不断刷新 `http://localhost:30080`）：
```bash
for i in {1..10}; do curl http://localhost:30080; echo ""; done
```
**见证奇迹的时刻**：你会发现，大约有 75% 的请求返回了“V 1 版本”，有 25% 的请求返回了“V 2 版本”！
*💡 测试视角抽象：这就是最基础的灰度发布模型！在线上，你可以先放出 1 个 V 2 节点，结合**线上监控**观察它的错误率。如果没问题，再逐渐把 V 1 的副本数降为 0，V 2 升为 3，完成平滑升级。如果发现 V 2 报错，直接 `kubectl delete -f canary.yaml`，瞬间回滚！*

---

### 总结：你的结构化收获
通过这 4 个 Demo，你已经在脑海中建立了一个立体的系统抽象模型：
1. **Docker** 解决了**环境一致性**和**可测性**。
2. **K 8 s Deployment** 解决了**高可用**和**故障预防**。
3. **K 8 s Service** 解决了**网络通信**和**负载均衡**。
4. **多 Deployment 组合** 实现了你心心念念的**灰度发布**。

建议你亲手把这几个命令敲一遍，遇到报错去查一下，当你看到 V 1 和 V 2 交替出现的那一刻，你对云原生架构的理解将彻底从“概念”变成“肌肉记忆”！